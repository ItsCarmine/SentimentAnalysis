{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b122db75-781d-45ff-8ad9-f78658ed4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizer, \n",
    "    RobertaForSequenceClassification,\n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec86eae-f0bb-4a91-9733-bd50de524b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare datasets\n",
    "train_df = pd.read_csv('datasets/imdb_dataset_sampled_300.csv')\n",
    "test_df = pd.read_csv('datasets/imdb_dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c95eb765-424d-48ef-a7c7-a0a305f3b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiments to numbers (assuming binary sentiment)\n",
    "label_map = {'positive': 1, 'negative': 0}\n",
    "train_df['sentiment'] = train_df['sentiment'].map(label_map)\n",
    "test_df['sentiment'] = test_df['sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b3c995a-c1ca-41ff-a456-c01cd6a669c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193c3b9776d04c829e5c4727adba64d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7486bb165a49d9aac353e56d789707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': train_df['review'].tolist(),\n",
    "    'label': train_df['sentiment'].tolist()\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'text': test_df['review'].tolist(),\n",
    "    'label': test_df['sentiment'].tolist()\n",
    "})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e43c731-20c5-475d-8173-bb2b32df5395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmine\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 02:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.694300</td>\n",
       "      <td>0.691572</td>\n",
       "      <td>0.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.685921</td>\n",
       "      <td>0.527300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.703203</td>\n",
       "      <td>0.672500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: {'eval_loss': 0.6859205365180969, 'eval_accuracy': 0.5273, 'eval_runtime': 47.8941, 'eval_samples_per_second': 208.794, 'eval_steps_per_second': 26.099, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Set format for PyTorch\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': accuracy_score(labels, predictions)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "test_results = trainer.evaluate()\n",
    "print(f\"Test results: {test_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
